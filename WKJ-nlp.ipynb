{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WKJ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP: Word2Vec\n",
    "\n",
    "### Encoding + Classification = Embedding\n",
    "\n",
    "https://medium.com/@patrykmwieczorek/mastering-nlp-with-pytorch-word2vec-60a54030c720\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html\n",
    "\n",
    "# TODO: Add Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q -P ./data/text https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/datasets/text/dickinson.txt\n",
    "!wget -qO- https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/datasets/text/rappers.tar.gz | tar xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import string\n",
    "import torch\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchtext.data import get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_1000_url = \"https://gist.githubusercontent.com/rg089/35e00abf8941d72d419224cfd5b5925d/raw/12d899b70156fd0041fa9778d657330b024b959c/stopwords.txt\"\n",
    "stop_100_url  = \"https://gist.githubusercontent.com/sebleier/554280/raw/7e0e4a1ce04c2bb7bd41089c9821dbcf6d0c786c/NLTK's%2520list%2520of%2520english%2520stopwords\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_100_list = requests.get(stop_100_url).content\n",
    "stopwords_100 = list(set(stopwords_100_list.decode().splitlines()))\n",
    "\n",
    "stopwords_1000_list = requests.get(stop_1000_url).content\n",
    "stopwords_1000 = list(set(stopwords_1000_list.decode().splitlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(text, max_words=200_000):\n",
    "\t# create one big string \n",
    "\ttext = \" \".join(text)\n",
    "\n",
    "\t# remove punctuation, whitespaces and convert to lowercase\n",
    "\ttext = text.translate(str.maketrans('', '', string.punctuation)).lower().strip()\n",
    "\n",
    "\t# tokenize words\n",
    "\ttokenizer = get_tokenizer(\"basic_english\")\n",
    "\twords = tokenizer(\"\".join(text))\n",
    "\treturn words[:max_words]\n",
    "\n",
    "def create_vocab(text, max_words=200_000):\n",
    "\twords = get_words(text, max_words=max_words)\n",
    "\t# remove repeated words\n",
    "\treturn words, list(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/text/dickinson.txt\", \"r\") as f:\n",
    "  txt = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_df = pd.read_csv(\"./data/text/rappers.csv\")\n",
    "txt = lyrics_df[\"lyric\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, vocab = create_vocab(txt, max_words=500_000)\n",
    "\n",
    "wtoi = {word: i for i, word in enumerate([\"<UNK>\"] + vocab)}\n",
    "wtoi = defaultdict(int, wtoi)\n",
    "\n",
    "itow = {i: word for i, word in enumerate(wtoi)}\n",
    "itow = defaultdict(lambda: \"<UNK>\", itow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wtoi), len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramDataset(Dataset):\n",
    "\tdef __init__(self, data, window=2, symmetric_context=True):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\t\tself.dataset = []\n",
    "\t\tself.window = window\n",
    "\t\tself.symmetric_context = symmetric_context\n",
    "\t\tself.X, self.Y = self.create_dataset(data)\n",
    "\t\tassert len(self.X) == len(self.Y)\n",
    "\n",
    "\tdef create_dataset(self, data):\n",
    "\t\tstopwords = stopwords_100 + [\"=\", \":\", \",\", \"(\", \")\", \"{\", \"}\", \"[\", \"]\"]\n",
    "\t\twindow = self.window\n",
    "\t\txs, ys = [], []\n",
    "\n",
    "\t\tfor i in range(0, len(data)):\n",
    "\t\t\tminj = i - window if self.symmetric_context else i + 1\n",
    "\t\t\tmaxj = i + window\n",
    "\t\t\tif data[i] in stopwords:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tcenter_word = wtoi[data[i]]\n",
    "\t\t\tfor j in range(minj, maxj + 1):\n",
    "\t\t\t\tif j == i or j < 0 or j > len(data)-1 or data[j] in stopwords:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tcontext_word = wtoi[data[j]]\n",
    "\t\t\t\txs.append(center_word)\n",
    "\t\t\t\tys.append(context_word)\n",
    "\t\treturn Tensor(xs).long().to(self.device), Tensor(ys).long().to(self.device)\n",
    "\n",
    "\tdef __getitem__(self, val):\n",
    "\t\tif type(val) is slice:\n",
    "\t\t\treturn list(zip(self.X[val], self.Y[val]))\n",
    "\t\treturn (self.X[val], self.Y[val])\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGram(nn.Module):\n",
    "\tdef __init__(self, vocab_size, embed_dim=128):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.center_embeds = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim)\n",
    "\t\tself.context_embeds = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tcenter_word = self.center_embeds(x)\n",
    "\t\tscores = torch.matmul(center_word, self.context_embeds.weight.t())\n",
    "\t\treturn scores\n",
    "\n",
    "\tdef get_N_closest(self, x, N=5, metric=\"lnorm\"):\n",
    "\t\t# get word vector\n",
    "\t\tx = self.center_embeds(x)\n",
    "\n",
    "\t\t# calculate similarity between x and all center vectors\n",
    "\t\tif metric == \"sine\":\n",
    "\t\t\tcos_sim = nn.CosineSimilarity()\n",
    "\t\t\tsimilarities = cos_sim(x, self.center_embeds.weight).squeeze()\n",
    "\t\t\tlargest = True\n",
    "\t\telif metric == \"lnorm\":\n",
    "\t\t\tsimilarities = torch.cdist(x, self.center_embeds.weight).squeeze()\n",
    "\t\t\tlargest = False\n",
    "\n",
    "\t\t# return top-N similar words by embeddings\n",
    "\t\tvalues, indices = torch.topk(similarities, k=N, largest=largest)\n",
    "\t\treturn indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SkipGramDataset(window=3, data=words, symmetric_context=False)\n",
    "train_dl = DataLoader(dataset, batch_size=4096, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = SkipGram(len(wtoi), embed_dim=64).to(mdevice)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "ctr,_ = next(iter(train_dl))\n",
    "ctx = model(ctr)\n",
    "\n",
    "print(ctr.shape, ctx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(32):\n",
    "  model.train()\n",
    "  for center, context in train_dl:\n",
    "    optim.zero_grad()\n",
    "    context_pred = model(center)\n",
    "    loss = loss_fn(context_pred, context)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "  if e % 4 == 3:\n",
    "    print(f\"Epoch: {e} loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = Tensor([wtoi[\"wild\"]]).long().to(mdevice)\n",
    "\n",
    "top5s = model.get_N_closest(query, metric=\"sine\")\n",
    "top5l = model.get_N_closest(query, metric=\"lnorm\")\n",
    "\n",
    "print([itow[i.item()] for i in top5s])\n",
    "print([itow[i.item()] for i in top5l])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNs\n",
    "\n",
    "### Classification + Classification + Classification + ...\n",
    "\n",
    "- Output of NN becomes an input for next prediction\n",
    "\n",
    "# TODO: Images\n",
    "\n",
    "https://machinelearningmastery.com/lstm-for-time-series-prediction-in-pytorch/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gradio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
